{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5f456ea",
   "metadata": {},
   "source": [
    "### Basic working of backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c925fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bdf80ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "\n",
    "w = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3550349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass to compute loss\n",
    "y_hat = w*x\n",
    "loss = (y_hat-y)**2\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05e02fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4d339fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Updating weight before next forward-backward pass\n",
    "## Wrap it using the \"with\" command"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b272f2",
   "metadata": {},
   "source": [
    "### Linear regerssion from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "687281ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fd06903a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "Loss after epoch 1 is 30.0000000000\n",
      "Loss after epoch 11 is 1.1627856493\n",
      "Loss after epoch 21 is 0.0450690463\n",
      "Loss after epoch 31 is 0.0017468547\n",
      "Loss after epoch 41 is 0.0000677049\n",
      "Loss after epoch 51 is 0.0000026244\n",
      "Loss after epoch 61 is 0.0000001018\n",
      "Loss after epoch 71 is 0.0000000039\n",
      "Loss after epoch 81 is 0.0000000002\n",
      "Loss after epoch 91 is 0.0000000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "X = np.array([1,2,3,4], dtype=np.float32)\n",
    "Y = np.array([2,4,6,8], dtype=np.float32)\n",
    "\n",
    "w = 0.0 ## We are omitting any bias for now\n",
    "\n",
    "# Model prediction\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "# Loss\n",
    "def loss(y, y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "\n",
    "# Gradient\n",
    "def gradient(x,y,y_pred):\n",
    "    return np.mean(2*x*(y_pred-y))\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "#Training\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    Y_pred = forward(X)\n",
    "    l = loss(Y,Y_pred)\n",
    "    dw = gradient(X,Y,Y_pred)\n",
    "    \n",
    "    w = w - learning_rate*dw\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        print(f\"Loss after epoch {epoch+1} is {l:.10f}\")\n",
    "    \n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bf4e1",
   "metadata": {},
   "source": [
    "### Linear regression using autograd for gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "71c14c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f0044bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "Loss after epoch 1 is 30.0000000000\n",
      "Loss after epoch 11 is 1.1627856493\n",
      "Loss after epoch 21 is 0.0450688973\n",
      "Loss after epoch 31 is 0.0017468547\n",
      "Loss after epoch 41 is 0.0000677049\n",
      "Loss after epoch 51 is 0.0000026244\n",
      "Loss after epoch 61 is 0.0000001018\n",
      "Loss after epoch 71 is 0.0000000040\n",
      "Loss after epoch 81 is 0.0000000001\n",
      "Loss after epoch 91 is 0.0000000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "def loss(y,y_pred):\n",
    "    return ((y-y_pred)**2).mean()\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "#Training\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    Y_pred = forward(X)\n",
    "    l = loss(Y,Y_pred)\n",
    "#     dw = gradient(X,Y,Y_pred)\n",
    "\n",
    "    l.backward()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "   \n",
    "    #Resetting the gradient to 0\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        print(f\"Loss after epoch {epoch+1} is {l:.10f}\")\n",
    "    \n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0bc4c2",
   "metadata": {},
   "source": [
    "### Linear regression with autograd, nn and optim packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "37a549aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we do not calculate the loss or update the weights manually. Rather, we use torch.nn adn torch.optim to utilise their modules for loss and optimizers.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b50a9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = 0.000\n",
      "Loss after epoch 1 is 30.0000000000\n",
      "Loss after epoch 11 is 1.1627856493\n",
      "Loss after epoch 21 is 0.0450688973\n",
      "Loss after epoch 31 is 0.0017468547\n",
      "Loss after epoch 41 is 0.0000677049\n",
      "Loss after epoch 51 is 0.0000026244\n",
      "Loss after epoch 61 is 0.0000001018\n",
      "Loss after epoch 71 is 0.0000000040\n",
      "Loss after epoch 81 is 0.0000000001\n",
      "Loss after epoch 91 is 0.0000000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8], dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
    "\n",
    "#Training\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "\n",
    "loss = nn.MSELoss() ## No need for hyperparameter setting here\n",
    "optimizer = opt.SGD([w], lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    Y_pred = forward(X)\n",
    "    l = loss(Y,Y_pred) ## Using the \"loss\" object that we created\n",
    "#     dw = gradient(X,Y,Y_pred)\n",
    "\n",
    "    l.backward()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         w -= learning_rate * w.grad\n",
    "\n",
    "    optimizer.step()\n",
    "   \n",
    "    #Resetting the gradient to 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        print(f\"Loss after epoch {epoch+1} is {l:.10f}\")\n",
    "    \n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3550c63",
   "metadata": {},
   "source": [
    "NOTE : Here, we define objects for `loss` and `optimizer`, wherein we instantiate the `optimizer` with our required hyperparameters(`learning_rate` for now). The `loss` object doesn't require any pre-setting. It just needs input and gives the corresponding loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252a80b",
   "metadata": {},
   "source": [
    "We call the `loss` with the target values and predicted values(`Y` and `Y_pred`) as input to the function(actual parameter). We then use the autograd's functionality of calling the `backward()` method on the loss, since we have already initialised `w` with `requires_grad` to be True. Thus, this sets the gradient of `w`. Now we call the optimizer and send the parameters in a list, and other hyperparameters also(here, `w` and `learning_rate`). Then we use the step method for updating(wraps it with `torch.no_grad()` by default), ad finally reset the gradient to 0 using `optimizer.grad_zero()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f9577c",
   "metadata": {},
   "source": [
    "### Creating a model to be used for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b48a3d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64d877",
   "metadata": {},
   "source": [
    "NOTE : For any model in pytorch, the input tensor and the target variable tensor should be a 2D tensor and should be of the form (number_of_input_samples, number_of_input_features). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "16072871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before training: f(5) = -4.633\n",
      "Weight and bias after 1 epoch are -0.5526863932609558 and 0.4392426908016205\n",
      "Loss after epoch 1 is 62.5310745239\n",
      "Weight and bias after 11 epoch are 1.2667009830474854 and 1.019435167312622\n",
      "Loss after epoch 11 is 1.8291726112\n",
      "Weight and bias after 21 epoch are 1.5688797235488892 and 1.0847325325012207\n",
      "Loss after epoch 21 is 0.2463684976\n",
      "Weight and bias after 31 epoch are 1.6267356872558594 and 1.0680372714996338\n",
      "Loss after epoch 31 is 0.1938321590\n",
      "Weight and bias after 41 epoch are 1.645019292831421 and 1.0389572381973267\n",
      "Loss after epoch 41 is 0.1815619469\n",
      "Weight and bias after 51 epoch are 1.6566723585128784 and 1.0086647272109985\n",
      "Loss after epoch 51 is 0.1709685177\n",
      "Weight and bias after 61 epoch are 1.6670016050338745 and 0.9789338111877441\n",
      "Loss after epoch 61 is 0.1610166281\n",
      "Weight and bias after 71 epoch are 1.676868200302124 and 0.9500274658203125\n",
      "Loss after epoch 71 is 0.1516446322\n",
      "Weight and bias after 81 epoch are 1.686418056488037 and 0.9219662547111511\n",
      "Loss after epoch 81 is 0.1428181082\n",
      "Weight and bias after 91 epoch are 1.6956815719604492 and 0.894732654094696\n",
      "Loss after epoch 91 is 0.1345053315\n",
      "Weight and bias after 101 epoch are 1.7046709060668945 and 0.8683033585548401\n",
      "Loss after epoch 101 is 0.1266764551\n",
      "Weight and bias after 111 epoch are 1.7133947610855103 and 0.8426545858383179\n",
      "Loss after epoch 111 is 0.1193031967\n",
      "Weight and bias after 121 epoch are 1.721860647201538 and 0.8177635669708252\n",
      "Loss after epoch 121 is 0.1123591438\n",
      "Weight and bias after 131 epoch are 1.730076551437378 and 0.7936077117919922\n",
      "Loss after epoch 131 is 0.1058192030\n",
      "Weight and bias after 141 epoch are 1.7380497455596924 and 0.7701655030250549\n",
      "Loss after epoch 141 is 0.0996600538\n",
      "Weight and bias after 151 epoch are 1.745787501335144 and 0.7474156618118286\n",
      "Loss after epoch 151 is 0.0938593373\n",
      "Weight and bias after 161 epoch are 1.7532967329025269 and 0.7253378033638\n",
      "Loss after epoch 161 is 0.0883962363\n",
      "Weight and bias after 171 epoch are 1.7605839967727661 and 0.7039121389389038\n",
      "Loss after epoch 171 is 0.0832510442\n",
      "Weight and bias after 181 epoch are 1.7676560878753662 and 0.6831192970275879\n",
      "Loss after epoch 181 is 0.0784054101\n",
      "Weight and bias after 191 epoch are 1.7745192050933838 and 0.6629407405853271\n",
      "Loss after epoch 191 is 0.0738418177\n",
      "Weight and bias after 201 epoch are 1.781179666519165 and 0.6433582901954651\n",
      "Loss after epoch 201 is 0.0695438161\n",
      "Weight and bias after 211 epoch are 1.787643313407898 and 0.6243543028831482\n",
      "Loss after epoch 211 is 0.0654960126\n",
      "Weight and bias after 221 epoch are 1.7939162254333496 and 0.6059115529060364\n",
      "Loss after epoch 221 is 0.0616838373\n",
      "Weight and bias after 231 epoch are 1.8000036478042603 and 0.5880135893821716\n",
      "Loss after epoch 231 is 0.0580934659\n",
      "Weight and bias after 241 epoch are 1.8059114217758179 and 0.5706443190574646\n",
      "Loss after epoch 241 is 0.0547120981\n",
      "Weight and bias after 251 epoch are 1.8116445541381836 and 0.5537881255149841\n",
      "Loss after epoch 251 is 0.0515276380\n",
      "Weight and bias after 261 epoch are 1.8172082901000977 and 0.537429928779602\n",
      "Loss after epoch 261 is 0.0485284440\n",
      "Weight and bias after 271 epoch are 1.8226077556610107 and 0.5215548872947693\n",
      "Loss after epoch 271 is 0.0457038730\n",
      "Weight and bias after 281 epoch are 1.8278477191925049 and 0.5061487555503845\n",
      "Loss after epoch 281 is 0.0430436656\n",
      "Weight and bias after 291 epoch are 1.832932949066162 and 0.4911976754665375\n",
      "Loss after epoch 291 is 0.0405382812\n",
      "Weight and bias after 301 epoch are 1.8378678560256958 and 0.4766882658004761\n",
      "Loss after epoch 301 is 0.0381787382\n",
      "Weight and bias after 311 epoch are 1.8426570892333984 and 0.4626074433326721\n",
      "Loss after epoch 311 is 0.0359565690\n",
      "Weight and bias after 321 epoch are 1.8473048210144043 and 0.44894251227378845\n",
      "Loss after epoch 321 is 0.0338636972\n",
      "Weight and bias after 331 epoch are 1.8518152236938477 and 0.4356812834739685\n",
      "Loss after epoch 331 is 0.0318926461\n",
      "Weight and bias after 341 epoch are 1.8561923503875732 and 0.4228118360042572\n",
      "Loss after epoch 341 is 0.0300363638\n",
      "Weight and bias after 351 epoch are 1.8604402542114258 and 0.4103224575519562\n",
      "Loss after epoch 351 is 0.0282880682\n",
      "Weight and bias after 361 epoch are 1.864562749862671 and 0.3982020318508148\n",
      "Loss after epoch 361 is 0.0266415756\n",
      "Weight and bias after 371 epoch are 1.8685635328292847 and 0.3864395320415497\n",
      "Loss after epoch 371 is 0.0250908770\n",
      "Weight and bias after 381 epoch are 1.8724459409713745 and 0.3750245273113251\n",
      "Loss after epoch 381 is 0.0236304495\n",
      "Weight and bias after 391 epoch are 1.876213788986206 and 0.36394673585891724\n",
      "Loss after epoch 391 is 0.0222550351\n",
      "Weight and bias after 401 epoch are 1.8798701763153076 and 0.3531961441040039\n",
      "Loss after epoch 401 is 0.0209596753\n",
      "Weight and bias after 411 epoch are 1.8834186792373657 and 0.34276318550109863\n",
      "Loss after epoch 411 is 0.0197397284\n",
      "Weight and bias after 421 epoch are 1.8868623971939087 and 0.33263838291168213\n",
      "Loss after epoch 421 is 0.0185908023\n",
      "Weight and bias after 431 epoch are 1.8902043104171753 and 0.32281264662742615\n",
      "Loss after epoch 431 is 0.0175087210\n",
      "Weight and bias after 441 epoch are 1.8934475183486938 and 0.31327709555625916\n",
      "Loss after epoch 441 is 0.0164895989\n",
      "Weight and bias after 451 epoch are 1.8965950012207031 and 0.30402329564094543\n",
      "Loss after epoch 451 is 0.0155298170\n",
      "Weight and bias after 461 epoch are 1.8996495008468628 and 0.29504281282424927\n",
      "Loss after epoch 461 is 0.0146259014\n",
      "Weight and bias after 471 epoch are 1.9026137590408325 and 0.2863275706768036\n",
      "Loss after epoch 471 is 0.0137745980\n",
      "Weight and bias after 481 epoch are 1.9054903984069824 and 0.2778698205947876\n",
      "Loss after epoch 481 is 0.0129728727\n",
      "Weight and bias after 491 epoch are 1.908281922340393 and 0.26966193318367004\n",
      "Loss after epoch 491 is 0.0122177927\n",
      "Weight and bias after 501 epoch are 1.9109913110733032 and 0.26169639825820923\n",
      "Loss after epoch 501 is 0.0115066487\n",
      "Weight and bias after 511 epoch are 1.9136205911636353 and 0.25396621227264404\n",
      "Loss after epoch 511 is 0.0108369058\n",
      "Weight and bias after 521 epoch are 1.9161721467971802 and 0.2464642971754074\n",
      "Loss after epoch 521 is 0.0102061359\n",
      "Weight and bias after 531 epoch are 1.9186482429504395 and 0.23918400704860687\n",
      "Loss after epoch 531 is 0.0096120769\n",
      "Weight and bias after 541 epoch are 1.9210515022277832 and 0.23211877048015594\n",
      "Loss after epoch 541 is 0.0090526110\n",
      "Weight and bias after 551 epoch are 1.9233834743499756 and 0.22526215016841888\n",
      "Loss after epoch 551 is 0.0085256798\n",
      "Weight and bias after 561 epoch are 1.9256466627120972 and 0.21860814094543457\n",
      "Loss after epoch 561 is 0.0080294376\n",
      "Weight and bias after 571 epoch are 1.9278429746627808 and 0.2121506631374359\n",
      "Loss after epoch 571 is 0.0075620958\n",
      "Weight and bias after 581 epoch are 1.9299744367599487 and 0.2058839350938797\n",
      "Loss after epoch 581 is 0.0071219318\n",
      "Weight and bias after 591 epoch are 1.9320428371429443 and 0.19980235397815704\n",
      "Loss after epoch 591 is 0.0067073936\n",
      "Weight and bias after 601 epoch are 1.9340500831604004 and 0.1939004510641098\n",
      "Loss after epoch 601 is 0.0063170041\n",
      "Weight and bias after 611 epoch are 1.9359983205795288 and 0.1881728619337082\n",
      "Loss after epoch 611 is 0.0059493231\n",
      "Weight and bias after 621 epoch are 1.9378888607025146 and 0.18261447548866272\n",
      "Loss after epoch 621 is 0.0056030392\n",
      "Weight and bias after 631 epoch are 1.9397234916687012 and 0.17722025513648987\n",
      "Loss after epoch 631 is 0.0052769119\n",
      "Weight and bias after 641 epoch are 1.9415040016174316 and 0.17198535799980164\n",
      "Loss after epoch 641 is 0.0049697789\n",
      "Weight and bias after 651 epoch are 1.9432319402694702 and 0.16690509021282196\n",
      "Loss after epoch 651 is 0.0046804994\n",
      "Weight and bias after 661 epoch are 1.9449087381362915 and 0.1619749218225479\n",
      "Loss after epoch 661 is 0.0044080811\n",
      "Weight and bias after 671 epoch are 1.9465360641479492 and 0.15719039738178253\n",
      "Loss after epoch 671 is 0.0041515096\n",
      "Weight and bias after 681 epoch are 1.948115587234497 and 0.15254710614681244\n",
      "Loss after epoch 681 is 0.0039098621\n",
      "Weight and bias after 691 epoch are 1.949648141860962 and 0.14804095029830933\n",
      "Loss after epoch 691 is 0.0036822711\n",
      "Weight and bias after 701 epoch are 1.9511353969573975 and 0.14366798102855682\n",
      "Loss after epoch 701 is 0.0034679538\n",
      "Weight and bias after 711 epoch are 1.9525787830352783 and 0.1394241899251938\n",
      "Loss after epoch 711 is 0.0032660924\n",
      "Weight and bias after 721 epoch are 1.9539794921875 and 0.1353057622909546\n",
      "Loss after epoch 721 is 0.0030759866\n",
      "Weight and bias after 731 epoch are 1.955338954925537 and 0.13130900263786316\n",
      "Loss after epoch 731 is 0.0028969478\n",
      "Weight and bias after 741 epoch are 1.9566582441329956 and 0.127430260181427\n",
      "Loss after epoch 741 is 0.0027283444\n",
      "Weight and bias after 751 epoch are 1.9579384326934814 and 0.12366612255573273\n",
      "Loss after epoch 751 is 0.0025695367\n",
      "Weight and bias after 761 epoch are 1.9591807126998901 and 0.12001317739486694\n",
      "Loss after epoch 761 is 0.0024199723\n",
      "Weight and bias after 771 epoch are 1.9603865146636963 and 0.11646820604801178\n",
      "Loss after epoch 771 is 0.0022791235\n",
      "Weight and bias after 781 epoch are 1.9615566730499268 and 0.1130279004573822\n",
      "Loss after epoch 781 is 0.0021464676\n",
      "Weight and bias after 791 epoch are 1.962692379951477 and 0.10968919843435287\n",
      "Loss after epoch 791 is 0.0020215274\n",
      "Weight and bias after 801 epoch are 1.9637943506240845 and 0.10644907504320145\n",
      "Loss after epoch 801 is 0.0019038711\n",
      "Weight and bias after 811 epoch are 1.9648637771606445 and 0.10330469906330109\n",
      "Loss after epoch 811 is 0.0017930574\n",
      "Weight and bias after 821 epoch are 1.9659016132354736 and 0.10025319457054138\n",
      "Loss after epoch 821 is 0.0016886874\n",
      "Weight and bias after 831 epoch are 1.9669088125228882 and 0.09729185700416565\n",
      "Loss after epoch 831 is 0.0015903972\n",
      "Weight and bias after 841 epoch are 1.9678863286972046 and 0.0944179892539978\n",
      "Loss after epoch 841 is 0.0014978305\n",
      "Weight and bias after 851 epoch are 1.9688349962234497 and 0.09162897616624832\n",
      "Loss after epoch 851 is 0.0014106482\n",
      "Weight and bias after 861 epoch are 1.9697555303573608 and 0.08892235159873962\n",
      "Loss after epoch 861 is 0.0013285377\n",
      "Weight and bias after 871 epoch are 1.9706488847732544 and 0.08629567176103592\n",
      "Loss after epoch 871 is 0.0012512106\n",
      "Weight and bias after 881 epoch are 1.9715158939361572 and 0.08374660462141037\n",
      "Loss after epoch 881 is 0.0011783814\n",
      "Weight and bias after 891 epoch are 1.9723572731018066 and 0.08127286285161972\n",
      "Loss after epoch 891 is 0.0011098012\n",
      "Weight and bias after 901 epoch are 1.9731738567352295 and 0.07887217402458191\n",
      "Loss after epoch 901 is 0.0010452004\n",
      "Weight and bias after 911 epoch are 1.9739664793014526 and 0.07654231786727905\n",
      "Loss after epoch 911 is 0.0009843586\n",
      "Weight and bias after 921 epoch are 1.9747353792190552 and 0.074281245470047\n",
      "Loss after epoch 921 is 0.0009270621\n",
      "Weight and bias after 931 epoch are 1.975481629371643 and 0.07208702713251114\n",
      "Loss after epoch 931 is 0.0008731077\n",
      "Weight and bias after 941 epoch are 1.976205825805664 and 0.06995765119791031\n",
      "Loss after epoch 941 is 0.0008222881\n",
      "Weight and bias after 951 epoch are 1.976908802986145 and 0.0678911805152893\n",
      "Loss after epoch 951 is 0.0007744231\n",
      "Weight and bias after 961 epoch are 1.9775909185409546 and 0.06588573008775711\n",
      "Loss after epoch 961 is 0.0007293515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight and bias after 971 epoch are 1.9782527685165405 and 0.06393951922655106\n",
      "Loss after epoch 971 is 0.0006868963\n",
      "Weight and bias after 981 epoch are 1.9788951873779297 and 0.06205080822110176\n",
      "Loss after epoch 981 is 0.0006469181\n",
      "Weight and bias after 991 epoch are 1.9795185327529907 and 0.06021789088845253\n",
      "Loss after epoch 991 is 0.0006092641\n",
      "Weight and bias after 1001 epoch are 1.980123519897461 and 0.058439161628484726\n",
      "Loss after epoch 1001 is 0.0005737978\n",
      "Weight and bias after 1011 epoch are 1.9807106256484985 and 0.05671295151114464\n",
      "Loss after epoch 1011 is 0.0005403999\n",
      "Weight and bias after 1021 epoch are 1.9812804460525513 and 0.0550377294421196\n",
      "Loss after epoch 1021 is 0.0005089474\n",
      "Weight and bias after 1031 epoch are 1.9818334579467773 and 0.05341199040412903\n",
      "Loss after epoch 1031 is 0.0004793264\n",
      "Weight and bias after 1041 epoch are 1.9823700189590454 and 0.051834236830472946\n",
      "Loss after epoch 1041 is 0.0004514238\n",
      "Weight and bias after 1051 epoch are 1.9828908443450928 and 0.05030311271548271\n",
      "Loss after epoch 1051 is 0.0004251537\n",
      "Weight and bias after 1061 epoch are 1.9833961725234985 and 0.0488172210752964\n",
      "Loss after epoch 1061 is 0.0004004038\n",
      "Weight and bias after 1071 epoch are 1.9838865995407104 and 0.04737520217895508\n",
      "Loss after epoch 1071 is 0.0003771003\n",
      "Weight and bias after 1081 epoch are 1.9843626022338867 and 0.04597581550478935\n",
      "Loss after epoch 1081 is 0.0003551514\n",
      "Weight and bias after 1091 epoch are 1.9848244190216064 and 0.04461777210235596\n",
      "Loss after epoch 1091 is 0.0003344776\n",
      "Weight and bias after 1101 epoch are 1.9852726459503174 and 0.043299853801727295\n",
      "Loss after epoch 1101 is 0.0003150146\n",
      "Weight and bias after 1111 epoch are 1.9857076406478882 and 0.04202086478471756\n",
      "Loss after epoch 1111 is 0.0002966750\n",
      "Weight and bias after 1121 epoch are 1.9861299991607666 and 0.040779635310173035\n",
      "Loss after epoch 1121 is 0.0002794054\n",
      "Weight and bias after 1131 epoch are 1.9865394830703735 and 0.039575088769197464\n",
      "Loss after epoch 1131 is 0.0002631453\n",
      "Weight and bias after 1141 epoch are 1.9869370460510254 and 0.038406167179346085\n",
      "Loss after epoch 1141 is 0.0002478318\n",
      "Weight and bias after 1151 epoch are 1.9873229265213013 and 0.037271782755851746\n",
      "Loss after epoch 1151 is 0.0002334086\n",
      "Weight and bias after 1161 epoch are 1.9876976013183594 and 0.036170825362205505\n",
      "Loss after epoch 1161 is 0.0002198206\n",
      "Weight and bias after 1171 epoch are 1.9880610704421997 and 0.03510235622525215\n",
      "Loss after epoch 1171 is 0.0002070256\n",
      "Weight and bias after 1181 epoch are 1.988413691520691 and 0.034065425395965576\n",
      "Loss after epoch 1181 is 0.0001949733\n",
      "Weight and bias after 1191 epoch are 1.9887558221817017 and 0.03305916115641594\n",
      "Loss after epoch 1191 is 0.0001836282\n",
      "Weight and bias after 1201 epoch are 1.9890880584716797 and 0.03208262845873833\n",
      "Loss after epoch 1201 is 0.0001729403\n",
      "Weight and bias after 1211 epoch are 1.989410400390625 and 0.031134922057390213\n",
      "Loss after epoch 1211 is 0.0001628713\n",
      "Weight and bias after 1221 epoch are 1.9897232055664062 and 0.030215207487344742\n",
      "Loss after epoch 1221 is 0.0001533939\n",
      "Weight and bias after 1231 epoch are 1.9900267124176025 and 0.02932267263531685\n",
      "Loss after epoch 1231 is 0.0001444628\n",
      "Weight and bias after 1241 epoch are 1.9903212785720825 and 0.02845652401447296\n",
      "Loss after epoch 1241 is 0.0001360541\n",
      "Weight and bias after 1251 epoch are 1.9906071424484253 and 0.027615971863269806\n",
      "Loss after epoch 1251 is 0.0001281377\n",
      "Weight and bias after 1261 epoch are 1.9908846616744995 and 0.0268002450466156\n",
      "Loss after epoch 1261 is 0.0001206767\n",
      "Weight and bias after 1271 epoch are 1.9911539554595947 and 0.026008589193224907\n",
      "Loss after epoch 1271 is 0.0001136533\n",
      "Weight and bias after 1281 epoch are 1.99141526222229 and 0.025240303948521614\n",
      "Loss after epoch 1281 is 0.0001070378\n",
      "Weight and bias after 1291 epoch are 1.9916688203811646 and 0.024494750425219536\n",
      "Loss after epoch 1291 is 0.0001008092\n",
      "Weight and bias after 1301 epoch are 1.991914987564087 and 0.02377118542790413\n",
      "Loss after epoch 1301 is 0.0000949413\n",
      "Weight and bias after 1311 epoch are 1.9921537637710571 and 0.023068996146321297\n",
      "Loss after epoch 1311 is 0.0000894153\n",
      "Weight and bias after 1321 epoch are 1.9923853874206543 and 0.022387580946087837\n",
      "Loss after epoch 1321 is 0.0000842105\n",
      "Weight and bias after 1331 epoch are 1.9926103353500366 and 0.021726319566369057\n",
      "Loss after epoch 1331 is 0.0000793106\n",
      "Weight and bias after 1341 epoch are 1.9928287267684937 and 0.021084561944007874\n",
      "Loss after epoch 1341 is 0.0000746941\n",
      "Weight and bias after 1351 epoch are 1.9930404424667358 and 0.020461739972233772\n",
      "Loss after epoch 1351 is 0.0000703451\n",
      "Weight and bias after 1361 epoch are 1.993246078491211 and 0.01985735073685646\n",
      "Loss after epoch 1361 is 0.0000662517\n",
      "Weight and bias after 1371 epoch are 1.993445634841919 and 0.019270751625299454\n",
      "Loss after epoch 1371 is 0.0000623963\n",
      "Weight and bias after 1381 epoch are 1.9936392307281494 and 0.01870151050388813\n",
      "Loss after epoch 1381 is 0.0000587625\n",
      "Weight and bias after 1391 epoch are 1.9938271045684814 and 0.018149081617593765\n",
      "Loss after epoch 1391 is 0.0000553423\n",
      "Weight and bias after 1401 epoch are 1.9940093755722046 and 0.01761298067867756\n",
      "Loss after epoch 1401 is 0.0000521218\n",
      "Weight and bias after 1411 epoch are 1.9941864013671875 and 0.017092691734433174\n",
      "Loss after epoch 1411 is 0.0000490874\n",
      "Weight and bias after 1421 epoch are 1.9943580627441406 and 0.016587814316153526\n",
      "Loss after epoch 1421 is 0.0000462304\n",
      "Weight and bias after 1431 epoch are 1.9945247173309326 and 0.01609785109758377\n",
      "Loss after epoch 1431 is 0.0000435401\n",
      "Weight and bias after 1441 epoch are 1.994686484336853 and 0.015622344799339771\n",
      "Loss after epoch 1441 is 0.0000410050\n",
      "Weight and bias after 1451 epoch are 1.9948434829711914 and 0.01516086608171463\n",
      "Loss after epoch 1451 is 0.0000386187\n",
      "Weight and bias after 1461 epoch are 1.9949957132339478 and 0.014713034965097904\n",
      "Loss after epoch 1461 is 0.0000363722\n",
      "Weight and bias after 1471 epoch are 1.9951435327529907 and 0.01427844725549221\n",
      "Loss after epoch 1471 is 0.0000342532\n",
      "Weight and bias after 1481 epoch are 1.9952870607376099 and 0.013856676407158375\n",
      "Loss after epoch 1481 is 0.0000322608\n",
      "Weight and bias after 1491 epoch are 1.9954261779785156 and 0.01344736386090517\n",
      "Loss after epoch 1491 is 0.0000303821\n",
      "Weight and bias after 1501 epoch are 1.9955613613128662 and 0.01305016502737999\n",
      "Loss after epoch 1501 is 0.0000286148\n",
      "Weight and bias after 1511 epoch are 1.9956926107406616 and 0.01266466174274683\n",
      "Loss after epoch 1511 is 0.0000269489\n",
      "Weight and bias after 1521 epoch are 1.9958198070526123 and 0.012290519662201405\n",
      "Loss after epoch 1521 is 0.0000253800\n",
      "Weight and bias after 1531 epoch are 1.9959431886672974 and 0.011927438899874687\n",
      "Loss after epoch 1531 is 0.0000239022\n",
      "Weight and bias after 1541 epoch are 1.996062994003296 and 0.011575110256671906\n",
      "Loss after epoch 1541 is 0.0000225112\n",
      "Weight and bias after 1551 epoch are 1.9961793422698975 and 0.01123320683836937\n",
      "Loss after epoch 1551 is 0.0000212013\n",
      "Weight and bias after 1561 epoch are 1.996292233467102 and 0.010901377536356449\n",
      "Loss after epoch 1561 is 0.0000199670\n",
      "Weight and bias after 1571 epoch are 1.9964017868041992 and 0.010579349473118782\n",
      "Loss after epoch 1571 is 0.0000188055\n",
      "Weight and bias after 1581 epoch are 1.996508002281189 and 0.01026682648807764\n",
      "Loss after epoch 1581 is 0.0000177099\n",
      "Weight and bias after 1591 epoch are 1.9966111183166504 and 0.009963578544557095\n",
      "Loss after epoch 1591 is 0.0000166789\n",
      "Weight and bias after 1601 epoch are 1.996711254119873 and 0.009669280610978603\n",
      "Loss after epoch 1601 is 0.0000157082\n",
      "Weight and bias after 1611 epoch are 1.996808409690857 and 0.009383659809827805\n",
      "Loss after epoch 1611 is 0.0000147950\n",
      "Weight and bias after 1621 epoch are 1.9969027042388916 and 0.009106483310461044\n",
      "Loss after epoch 1621 is 0.0000139333\n",
      "Weight and bias after 1631 epoch are 1.9969942569732666 and 0.008837468922138214\n",
      "Loss after epoch 1631 is 0.0000131220\n",
      "Weight and bias after 1641 epoch are 1.9970829486846924 and 0.008576394990086555\n",
      "Loss after epoch 1641 is 0.0000123590\n",
      "Weight and bias after 1651 epoch are 1.9971691370010376 and 0.00832309015095234\n",
      "Loss after epoch 1651 is 0.0000116389\n",
      "Weight and bias after 1661 epoch are 1.9972527027130127 and 0.008077237755060196\n",
      "Loss after epoch 1661 is 0.0000109623\n",
      "Weight and bias after 1671 epoch are 1.9973338842391968 and 0.007838654331862926\n",
      "Loss after epoch 1671 is 0.0000103235\n",
      "Weight and bias after 1681 epoch are 1.9974125623703003 and 0.007607137784361839\n",
      "Loss after epoch 1681 is 0.0000097227\n",
      "Weight and bias after 1691 epoch are 1.9974889755249023 and 0.007382454350590706\n",
      "Loss after epoch 1691 is 0.0000091569\n",
      "Weight and bias after 1701 epoch are 1.997563123703003 and 0.007164423819631338\n",
      "Loss after epoch 1701 is 0.0000086247\n",
      "Weight and bias after 1711 epoch are 1.9976352453231812 and 0.00695283617824316\n",
      "Loss after epoch 1711 is 0.0000081218\n",
      "Weight and bias after 1721 epoch are 1.9977049827575684 and 0.00674747209995985\n",
      "Loss after epoch 1721 is 0.0000076496\n",
      "Weight and bias after 1731 epoch are 1.9977728128433228 and 0.006548148114234209\n",
      "Loss after epoch 1731 is 0.0000072040\n",
      "Weight and bias after 1741 epoch are 1.9978386163711548 and 0.006354719400405884\n",
      "Loss after epoch 1741 is 0.0000067846\n",
      "Weight and bias after 1751 epoch are 1.9979023933410645 and 0.006167028099298477\n",
      "Loss after epoch 1751 is 0.0000063906\n",
      "Weight and bias after 1761 epoch are 1.9979642629623413 and 0.005984873976558447\n",
      "Loss after epoch 1761 is 0.0000060183\n",
      "Weight and bias after 1771 epoch are 1.9980244636535645 and 0.005808139219880104\n",
      "Loss after epoch 1771 is 0.0000056679\n",
      "Weight and bias after 1781 epoch are 1.9980827569961548 and 0.005636580288410187\n",
      "Loss after epoch 1781 is 0.0000053383\n",
      "Weight and bias after 1791 epoch are 1.9981393814086914 and 0.005470131989568472\n",
      "Loss after epoch 1791 is 0.0000050278\n",
      "Weight and bias after 1801 epoch are 1.9981944561004639 and 0.005308560561388731\n",
      "Loss after epoch 1801 is 0.0000047350\n",
      "Weight and bias after 1811 epoch are 1.998247742652893 and 0.005151757504791021\n",
      "Loss after epoch 1811 is 0.0000044593\n",
      "Weight and bias after 1821 epoch are 1.998299479484558 and 0.00499959709122777\n",
      "Loss after epoch 1821 is 0.0000041999\n",
      "Weight and bias after 1831 epoch are 1.9983497858047485 and 0.004851940553635359\n",
      "Loss after epoch 1831 is 0.0000039551\n",
      "Weight and bias after 1841 epoch are 1.9983984231948853 and 0.004708639811724424\n",
      "Loss after epoch 1841 is 0.0000037253\n",
      "Weight and bias after 1851 epoch are 1.9984456300735474 and 0.004569580312818289\n",
      "Loss after epoch 1851 is 0.0000035085\n",
      "Weight and bias after 1861 epoch are 1.9984915256500244 and 0.004434665199369192\n",
      "Loss after epoch 1861 is 0.0000033043\n",
      "Weight and bias after 1871 epoch are 1.9985361099243164 and 0.004303717520087957\n",
      "Loss after epoch 1871 is 0.0000031119\n",
      "Weight and bias after 1881 epoch are 1.9985793828964233 and 0.004176621325314045\n",
      "Loss after epoch 1881 is 0.0000029311\n",
      "Weight and bias after 1891 epoch are 1.9986213445663452 and 0.0040532732382416725\n",
      "Loss after epoch 1891 is 0.0000027605\n",
      "Weight and bias after 1901 epoch are 1.9986621141433716 and 0.003933560568839312\n",
      "Loss after epoch 1901 is 0.0000026000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight and bias after 1911 epoch are 1.998701572418213 and 0.0038173971697688103\n",
      "Loss after epoch 1911 is 0.0000024483\n",
      "Weight and bias after 1921 epoch are 1.9987398386001587 and 0.0037046910729259253\n",
      "Loss after epoch 1921 is 0.0000023059\n",
      "Weight and bias after 1931 epoch are 1.9987770318984985 and 0.003595309564843774\n",
      "Loss after epoch 1931 is 0.0000021718\n",
      "Weight and bias after 1941 epoch are 1.9988131523132324 and 0.0034891560208052397\n",
      "Loss after epoch 1941 is 0.0000020454\n",
      "Weight and bias after 1951 epoch are 1.9988481998443604 and 0.003386115189641714\n",
      "Loss after epoch 1951 is 0.0000019264\n",
      "Weight and bias after 1961 epoch are 1.9988821744918823 and 0.0032861176878213882\n",
      "Loss after epoch 1961 is 0.0000018146\n",
      "Weight and bias after 1971 epoch are 1.9989153146743774 and 0.003189092967659235\n",
      "Loss after epoch 1971 is 0.0000017087\n",
      "Weight and bias after 1981 epoch are 1.9989473819732666 and 0.0030948999337852\n",
      "Loss after epoch 1981 is 0.0000016091\n",
      "Weight and bias after 1991 epoch are 1.9989783763885498 and 0.0030035211239010096\n",
      "Loss after epoch 1991 is 0.0000015158\n",
      "Weight and bias after 2001 epoch are 1.9990085363388062 and 0.0029148138128221035\n",
      "Loss after epoch 2001 is 0.0000014274\n",
      "Weight and bias after 2011 epoch are 1.999037742614746 and 0.002828724682331085\n",
      "Loss after epoch 2011 is 0.0000013444\n",
      "Weight and bias after 2021 epoch are 1.9990663528442383 and 0.0027452220674604177\n",
      "Loss after epoch 2021 is 0.0000012663\n",
      "Weight and bias after 2031 epoch are 1.999093770980835 and 0.002664162078872323\n",
      "Loss after epoch 2031 is 0.0000011924\n",
      "Weight and bias after 2041 epoch are 1.9991204738616943 and 0.0025854825507849455\n",
      "Loss after epoch 2041 is 0.0000011232\n",
      "Weight and bias after 2051 epoch are 1.999146580696106 and 0.0025091376155614853\n",
      "Loss after epoch 2051 is 0.0000010578\n",
      "Weight and bias after 2061 epoch are 1.9991717338562012 and 0.002435051603242755\n",
      "Loss after epoch 2061 is 0.0000009961\n",
      "Weight and bias after 2071 epoch are 1.9991960525512695 and 0.0023631316144019365\n",
      "Loss after epoch 2071 is 0.0000009382\n",
      "Weight and bias after 2081 epoch are 1.9992198944091797 and 0.0022934156004339457\n",
      "Loss after epoch 2081 is 0.0000008837\n",
      "Weight and bias after 2091 epoch are 1.999242901802063 and 0.0022256833035498857\n",
      "Loss after epoch 2091 is 0.0000008323\n",
      "Weight and bias after 2101 epoch are 1.999265432357788 and 0.0021599524188786745\n",
      "Loss after epoch 2101 is 0.0000007839\n",
      "Weight and bias after 2111 epoch are 1.9992868900299072 and 0.0020961957052350044\n",
      "Loss after epoch 2111 is 0.0000007382\n",
      "Weight and bias after 2121 epoch are 1.9993079900741577 and 0.0020342892967164516\n",
      "Loss after epoch 2121 is 0.0000006953\n",
      "Weight and bias after 2131 epoch are 1.999328374862671 and 0.0019742604345083237\n",
      "Loss after epoch 2131 is 0.0000006548\n",
      "Weight and bias after 2141 epoch are 1.9993482828140259 and 0.0019159589428454638\n",
      "Loss after epoch 2141 is 0.0000006169\n",
      "Weight and bias after 2151 epoch are 1.999367356300354 and 0.0018594441935420036\n",
      "Loss after epoch 2151 is 0.0000005810\n",
      "Weight and bias after 2161 epoch are 1.999386191368103 and 0.0018045494798570871\n",
      "Loss after epoch 2161 is 0.0000005472\n",
      "Weight and bias after 2171 epoch are 1.9994041919708252 and 0.0017512842314317822\n",
      "Loss after epoch 2171 is 0.0000005153\n",
      "Weight and bias after 2181 epoch are 1.9994219541549683 and 0.001699587912298739\n",
      "Loss after epoch 2181 is 0.0000004853\n",
      "Weight and bias after 2191 epoch are 1.9994388818740845 and 0.0016494079027324915\n",
      "Loss after epoch 2191 is 0.0000004571\n",
      "Weight and bias after 2201 epoch are 1.9994555711746216 and 0.0016007348895072937\n",
      "Loss after epoch 2201 is 0.0000004306\n",
      "Weight and bias after 2211 epoch are 1.9994715452194214 and 0.0015534516423940659\n",
      "Loss after epoch 2211 is 0.0000004054\n",
      "Weight and bias after 2221 epoch are 1.999487042427063 and 0.0015076538547873497\n",
      "Loss after epoch 2221 is 0.0000003819\n",
      "Weight and bias after 2231 epoch are 1.9995023012161255 and 0.001463145948946476\n",
      "Loss after epoch 2231 is 0.0000003596\n",
      "Weight and bias after 2241 epoch are 1.9995168447494507 and 0.0014199636643752456\n",
      "Loss after epoch 2241 is 0.0000003387\n",
      "Weight and bias after 2251 epoch are 1.9995311498641968 and 0.001378129469230771\n",
      "Loss after epoch 2251 is 0.0000003191\n",
      "Weight and bias after 2261 epoch are 1.9995450973510742 and 0.0013374147238209844\n",
      "Loss after epoch 2261 is 0.0000003006\n",
      "Weight and bias after 2271 epoch are 1.9995583295822144 and 0.0012979552848264575\n",
      "Loss after epoch 2271 is 0.0000002830\n",
      "Weight and bias after 2281 epoch are 1.999571442604065 and 0.0012596927117556334\n",
      "Loss after epoch 2281 is 0.0000002666\n",
      "Weight and bias after 2291 epoch are 1.9995843172073364 and 0.0012224888196215034\n",
      "Loss after epoch 2291 is 0.0000002511\n",
      "Weight and bias after 2301 epoch are 1.9995962381362915 and 0.0011864067055284977\n",
      "Loss after epoch 2301 is 0.0000002365\n",
      "Weight and bias after 2311 epoch are 1.9996081590652466 and 0.001151478267274797\n",
      "Loss after epoch 2311 is 0.0000002229\n",
      "Weight and bias after 2321 epoch are 1.9996198415756226 and 0.0011174953542649746\n",
      "Loss after epoch 2321 is 0.0000002098\n",
      "Weight and bias after 2331 epoch are 1.9996310472488403 and 0.0010845172218978405\n",
      "Loss after epoch 2331 is 0.0000001976\n",
      "Weight and bias after 2341 epoch are 1.9996417760849 and 0.0010525668039917946\n",
      "Loss after epoch 2341 is 0.0000001862\n",
      "Weight and bias after 2351 epoch are 1.9996525049209595 and 0.0010215495713055134\n",
      "Loss after epoch 2351 is 0.0000001754\n",
      "Weight and bias after 2361 epoch are 1.9996627569198608 and 0.0009913656394928694\n",
      "Loss after epoch 2361 is 0.0000001652\n",
      "Weight and bias after 2371 epoch are 1.999672532081604 and 0.0009621236240491271\n",
      "Loss after epoch 2371 is 0.0000001555\n",
      "Weight and bias after 2381 epoch are 1.999682068824768 and 0.0009338399977423251\n",
      "Loss after epoch 2381 is 0.0000001466\n",
      "Weight and bias after 2391 epoch are 1.9996916055679321 and 0.0009063753532245755\n",
      "Loss after epoch 2391 is 0.0000001380\n",
      "Weight and bias after 2401 epoch are 1.999700903892517 and 0.0008795986068435013\n",
      "Loss after epoch 2401 is 0.0000001300\n",
      "Weight and bias after 2411 epoch are 1.9997096061706543 and 0.0008536265231668949\n",
      "Loss after epoch 2411 is 0.0000001224\n",
      "Weight and bias after 2421 epoch are 1.9997180700302124 and 0.0008284769719466567\n",
      "Loss after epoch 2421 is 0.0000001153\n",
      "Weight and bias after 2431 epoch are 1.999726414680481 and 0.0008040806860662997\n",
      "Loss after epoch 2431 is 0.0000001087\n",
      "Weight and bias after 2441 epoch are 1.9997347593307495 and 0.0007803401676937938\n",
      "Loss after epoch 2441 is 0.0000001023\n",
      "Weight and bias after 2451 epoch are 1.9997423887252808 and 0.0007572481408715248\n",
      "Loss after epoch 2451 is 0.0000000963\n",
      "Weight and bias after 2461 epoch are 1.9997498989105225 and 0.0007348951767198741\n",
      "Loss after epoch 2461 is 0.0000000908\n",
      "Weight and bias after 2471 epoch are 1.999757170677185 and 0.0007132694008760154\n",
      "Loss after epoch 2471 is 0.0000000855\n",
      "Weight and bias after 2481 epoch are 1.999764323234558 and 0.0006923159235157073\n",
      "Loss after epoch 2481 is 0.0000000806\n",
      "Weight and bias after 2491 epoch are 1.9997714757919312 and 0.0006719251396134496\n",
      "Loss after epoch 2491 is 0.0000000759\n",
      "Weight and bias after 2501 epoch are 1.9997782707214355 and 0.0006520315073430538\n",
      "Loss after epoch 2501 is 0.0000000714\n",
      "Weight and bias after 2511 epoch are 1.9997847080230713 and 0.0006327697192318738\n",
      "Loss after epoch 2511 is 0.0000000672\n",
      "Weight and bias after 2521 epoch are 1.999790906906128 and 0.0006141253979876637\n",
      "Loss after epoch 2521 is 0.0000000634\n",
      "Weight and bias after 2531 epoch are 1.9997971057891846 and 0.0005960520938970149\n",
      "Loss after epoch 2531 is 0.0000000597\n",
      "Weight and bias after 2541 epoch are 1.999803066253662 and 0.0005785259418189526\n",
      "Loss after epoch 2541 is 0.0000000562\n",
      "Weight and bias after 2551 epoch are 1.9998090267181396 and 0.0005614826222881675\n",
      "Loss after epoch 2551 is 0.0000000530\n",
      "Weight and bias after 2561 epoch are 1.999814748764038 and 0.0005448576994240284\n",
      "Loss after epoch 2561 is 0.0000000499\n",
      "Weight and bias after 2571 epoch are 1.9998202323913574 and 0.0005287285894155502\n",
      "Loss after epoch 2571 is 0.0000000470\n",
      "Weight and bias after 2581 epoch are 1.9998254776000977 and 0.0005131193902343512\n",
      "Loss after epoch 2581 is 0.0000000443\n",
      "Weight and bias after 2591 epoch are 1.9998303651809692 and 0.0004980108351446688\n",
      "Loss after epoch 2591 is 0.0000000417\n",
      "Weight and bias after 2601 epoch are 1.9998353719711304 and 0.00048338391934521496\n",
      "Loss after epoch 2601 is 0.0000000392\n",
      "Weight and bias after 2611 epoch are 1.9998401403427124 and 0.0004692337824963033\n",
      "Loss after epoch 2611 is 0.0000000370\n",
      "Weight and bias after 2621 epoch are 1.9998449087142944 and 0.00045549136120826006\n",
      "Loss after epoch 2621 is 0.0000000349\n",
      "Weight and bias after 2631 epoch are 1.9998496770858765 and 0.0004420862824190408\n",
      "Loss after epoch 2631 is 0.0000000328\n",
      "Weight and bias after 2641 epoch are 1.9998542070388794 and 0.00042896607192233205\n",
      "Loss after epoch 2641 is 0.0000000309\n",
      "Weight and bias after 2651 epoch are 1.9998583793640137 and 0.00041625479934737086\n",
      "Loss after epoch 2651 is 0.0000000291\n",
      "Weight and bias after 2661 epoch are 1.999862551689148 and 0.0004039559862576425\n",
      "Loss after epoch 2661 is 0.0000000274\n",
      "Weight and bias after 2671 epoch are 1.9998664855957031 and 0.0003920374147128314\n",
      "Loss after epoch 2671 is 0.0000000258\n",
      "Weight and bias after 2681 epoch are 1.9998705387115479 and 0.00038050749571993947\n",
      "Loss after epoch 2681 is 0.0000000243\n",
      "Weight and bias after 2691 epoch are 1.999874234199524 and 0.000369330431567505\n",
      "Loss after epoch 2691 is 0.0000000229\n",
      "Weight and bias after 2701 epoch are 1.9998778104782104 and 0.0003585229569580406\n",
      "Loss after epoch 2701 is 0.0000000216\n",
      "Weight and bias after 2711 epoch are 1.999881386756897 and 0.0003480575978755951\n",
      "Loss after epoch 2711 is 0.0000000204\n",
      "Weight and bias after 2721 epoch are 1.9998849630355835 and 0.00033786759013310075\n",
      "Loss after epoch 2721 is 0.0000000192\n",
      "Weight and bias after 2731 epoch are 1.99988853931427 and 0.0003279111988376826\n",
      "Loss after epoch 2731 is 0.0000000181\n",
      "Weight and bias after 2741 epoch are 1.999891996383667 and 0.000318149192025885\n",
      "Loss after epoch 2741 is 0.0000000170\n",
      "Weight and bias after 2751 epoch are 1.9998952150344849 and 0.0003086768265347928\n",
      "Loss after epoch 2751 is 0.0000000160\n",
      "Weight and bias after 2761 epoch are 1.9998981952667236 and 0.00029950961470603943\n",
      "Loss after epoch 2761 is 0.0000000151\n",
      "Weight and bias after 2771 epoch are 1.9999011754989624 and 0.00029065116541460156\n",
      "Loss after epoch 2771 is 0.0000000142\n",
      "Weight and bias after 2781 epoch are 1.9999040365219116 and 0.0002820728695951402\n",
      "Loss after epoch 2781 is 0.0000000134\n",
      "Weight and bias after 2791 epoch are 1.9999067783355713 and 0.00027376640355214477\n",
      "Loss after epoch 2791 is 0.0000000126\n",
      "Weight and bias after 2801 epoch are 1.999909520149231 and 0.00026573645300231874\n",
      "Loss after epoch 2801 is 0.0000000119\n",
      "Weight and bias after 2811 epoch are 1.999912142753601 and 0.0002579449210315943\n",
      "Loss after epoch 2811 is 0.0000000112\n",
      "Weight and bias after 2821 epoch are 1.9999146461486816 and 0.0002504144504200667\n",
      "Loss after epoch 2821 is 0.0000000105\n",
      "Weight and bias after 2831 epoch are 1.9999171495437622 and 0.00024311406014021486\n",
      "Loss after epoch 2831 is 0.0000000099\n",
      "Weight and bias after 2841 epoch are 1.9999195337295532 and 0.0002360330254305154\n",
      "Loss after epoch 2841 is 0.0000000094\n",
      "Weight and bias after 2851 epoch are 1.9999219179153442 and 0.00022914631699677557\n",
      "Loss after epoch 2851 is 0.0000000088\n",
      "Weight and bias after 2861 epoch are 1.9999243021011353 and 0.00022242768318392336\n",
      "Loss after epoch 2861 is 0.0000000083\n",
      "Weight and bias after 2871 epoch are 1.9999266862869263 and 0.0002158485003747046\n",
      "Loss after epoch 2871 is 0.0000000078\n",
      "Weight and bias after 2881 epoch are 1.9999289512634277 and 0.00020939930982422084\n",
      "Loss after epoch 2881 is 0.0000000074\n",
      "Weight and bias after 2891 epoch are 1.99993097782135 and 0.00020314201537985355\n",
      "Loss after epoch 2891 is 0.0000000069\n",
      "Weight and bias after 2901 epoch are 1.9999330043792725 and 0.0001970766461454332\n",
      "Loss after epoch 2901 is 0.0000000065\n",
      "Weight and bias after 2911 epoch are 1.9999350309371948 and 0.00019122345838695765\n",
      "Loss after epoch 2911 is 0.0000000062\n",
      "Weight and bias after 2921 epoch are 1.9999369382858276 and 0.00018555625865701586\n",
      "Loss after epoch 2921 is 0.0000000058\n",
      "Weight and bias after 2931 epoch are 1.999938726425171 and 0.00018005592573899776\n",
      "Loss after epoch 2931 is 0.0000000054\n",
      "Weight and bias after 2941 epoch are 1.9999405145645142 and 0.00017472966283094138\n",
      "Loss after epoch 2941 is 0.0000000051\n",
      "Weight and bias after 2951 epoch are 1.9999421834945679 and 0.00016957506886683404\n",
      "Loss after epoch 2951 is 0.0000000048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight and bias after 2961 epoch are 1.9999439716339111 and 0.00016458974278066307\n",
      "Loss after epoch 2961 is 0.0000000046\n",
      "Weight and bias after 2971 epoch are 1.9999456405639648 and 0.00015975820133462548\n",
      "Loss after epoch 2971 is 0.0000000043\n",
      "Weight and bias after 2981 epoch are 1.999947190284729 and 0.00015508042997680604\n",
      "Loss after epoch 2981 is 0.0000000041\n",
      "Weight and bias after 2991 epoch are 1.9999486207962036 and 0.00015054570394568145\n",
      "Loss after epoch 2991 is 0.0000000038\n",
      "Weight and bias after 3001 epoch are 1.9999501705169678 and 0.0001461790525354445\n",
      "Loss after epoch 3001 is 0.0000000036\n",
      "Weight and bias after 3011 epoch are 1.9999516010284424 and 0.00014193398237694055\n",
      "Loss after epoch 3011 is 0.0000000034\n",
      "Weight and bias after 3021 epoch are 1.9999529123306274 and 0.0001378164888592437\n",
      "Loss after epoch 3021 is 0.0000000032\n",
      "Weight and bias after 3031 epoch are 1.999954342842102 and 0.0001338361034868285\n",
      "Loss after epoch 3031 is 0.0000000030\n",
      "Weight and bias after 3041 epoch are 1.9999555349349976 and 0.00012997612066101283\n",
      "Loss after epoch 3041 is 0.0000000028\n",
      "Weight and bias after 3051 epoch are 1.9999568462371826 and 0.00012624367082025856\n",
      "Loss after epoch 3051 is 0.0000000027\n",
      "Weight and bias after 3061 epoch are 1.9999580383300781 and 0.00012263876851648092\n",
      "Loss after epoch 3061 is 0.0000000025\n",
      "Weight and bias after 3071 epoch are 1.9999592304229736 and 0.00011913879279745743\n",
      "Loss after epoch 3071 is 0.0000000024\n",
      "Weight and bias after 3081 epoch are 1.9999604225158691 and 0.00011573536903597414\n",
      "Loss after epoch 3081 is 0.0000000023\n",
      "Weight and bias after 3091 epoch are 1.9999616146087646 and 0.0001124046539189294\n",
      "Loss after epoch 3091 is 0.0000000021\n",
      "Weight and bias after 3101 epoch are 1.9999628067016602 and 0.00010914190352195874\n",
      "Loss after epoch 3101 is 0.0000000020\n",
      "Weight and bias after 3111 epoch are 1.9999639987945557 and 0.00010592802573228255\n",
      "Loss after epoch 3111 is 0.0000000019\n",
      "Weight and bias after 3121 epoch are 1.9999651908874512 and 0.0001027618272928521\n",
      "Loss after epoch 3121 is 0.0000000018\n",
      "Weight and bias after 3131 epoch are 1.9999662637710571 and 9.963376942323521e-05\n",
      "Loss after epoch 3131 is 0.0000000017\n",
      "Weight and bias after 3141 epoch are 1.999967336654663 and 9.660704381531104e-05\n",
      "Loss after epoch 3141 is 0.0000000016\n",
      "Weight and bias after 3151 epoch are 1.9999682903289795 and 9.365780715597793e-05\n",
      "Loss after epoch 3151 is 0.0000000015\n",
      "Weight and bias after 3161 epoch are 1.999969244003296 and 9.081347525352612e-05\n",
      "Loss after epoch 3161 is 0.0000000014\n",
      "Weight and bias after 3171 epoch are 1.9999701976776123 and 8.806807454675436e-05\n",
      "Loss after epoch 3171 is 0.0000000013\n",
      "Weight and bias after 3181 epoch are 1.9999710321426392 and 8.539062400814146e-05\n",
      "Loss after epoch 3181 is 0.0000000012\n",
      "Weight and bias after 3191 epoch are 1.9999719858169556 and 8.281093323603272e-05\n",
      "Loss after epoch 3191 is 0.0000000011\n",
      "Weight and bias after 3201 epoch are 1.9999728202819824 and 8.03063521743752e-05\n",
      "Loss after epoch 3201 is 0.0000000011\n",
      "Weight and bias after 3211 epoch are 1.9999735355377197 and 7.787447975715622e-05\n",
      "Loss after epoch 3211 is 0.0000000010\n",
      "Weight and bias after 3221 epoch are 1.9999743700027466 and 7.552963506896049e-05\n",
      "Loss after epoch 3221 is 0.0000000010\n",
      "Weight and bias after 3231 epoch are 1.9999752044677734 and 7.326227205339819e-05\n",
      "Loss after epoch 3231 is 0.0000000009\n",
      "Weight and bias after 3241 epoch are 1.9999759197235107 and 7.107120472937822e-05\n",
      "Loss after epoch 3241 is 0.0000000008\n",
      "Weight and bias after 3251 epoch are 1.999976634979248 and 6.894094258313999e-05\n",
      "Loss after epoch 3251 is 0.0000000008\n",
      "Weight and bias after 3261 epoch are 1.9999772310256958 and 6.687386485282332e-05\n",
      "Loss after epoch 3261 is 0.0000000007\n",
      "Weight and bias after 3271 epoch are 1.9999780654907227 and 6.489259249065071e-05\n",
      "Loss after epoch 3271 is 0.0000000007\n",
      "Weight and bias after 3281 epoch are 1.9999786615371704 and 6.296974606812e-05\n",
      "Loss after epoch 3281 is 0.0000000007\n",
      "Weight and bias after 3291 epoch are 1.9999791383743286 and 6.10921997576952e-05\n",
      "Loss after epoch 3291 is 0.0000000006\n",
      "Weight and bias after 3301 epoch are 1.999979853630066 and 5.929690814809874e-05\n",
      "Loss after epoch 3301 is 0.0000000006\n",
      "Weight and bias after 3311 epoch are 1.9999804496765137 and 5.755168240284547e-05\n",
      "Loss after epoch 3311 is 0.0000000006\n",
      "Weight and bias after 3321 epoch are 1.9999810457229614 and 5.58565225219354e-05\n",
      "Loss after epoch 3321 is 0.0000000005\n",
      "Weight and bias after 3331 epoch are 1.9999815225601196 and 5.421858440968208e-05\n",
      "Loss after epoch 3331 is 0.0000000005\n",
      "Weight and bias after 3341 epoch are 1.9999819993972778 and 5.262595004751347e-05\n",
      "Loss after epoch 3341 is 0.0000000005\n",
      "Weight and bias after 3351 epoch are 1.9999825954437256 and 5.110126585350372e-05\n",
      "Loss after epoch 3351 is 0.0000000004\n",
      "Weight and bias after 3361 epoch are 1.9999830722808838 and 4.961115337209776e-05\n",
      "Loss after epoch 3361 is 0.0000000004\n",
      "Weight and bias after 3371 epoch are 1.999983549118042 and 4.81818278785795e-05\n",
      "Loss after epoch 3371 is 0.0000000004\n",
      "Weight and bias after 3381 epoch are 1.9999840259552002 and 4.678826735471375e-05\n",
      "Loss after epoch 3381 is 0.0000000004\n",
      "Weight and bias after 3391 epoch are 1.9999843835830688 and 4.5448359742295e-05\n",
      "Loss after epoch 3391 is 0.0000000003\n",
      "Weight and bias after 3401 epoch are 1.999984860420227 and 4.4141834223410115e-05\n",
      "Loss after epoch 3401 is 0.0000000003\n",
      "Weight and bias after 3411 epoch are 1.9999853372573853 and 4.28949024353642e-05\n",
      "Loss after epoch 3411 is 0.0000000003\n",
      "Weight and bias after 3421 epoch are 1.999985694885254 and 4.16682378272526e-05\n",
      "Loss after epoch 3421 is 0.0000000003\n",
      "Weight and bias after 3431 epoch are 1.999986171722412 and 4.050117786391638e-05\n",
      "Loss after epoch 3431 is 0.0000000003\n",
      "Weight and bias after 3441 epoch are 1.9999865293502808 and 3.935081258532591e-05\n",
      "Loss after epoch 3441 is 0.0000000003\n",
      "Weight and bias after 3451 epoch are 1.9999868869781494 and 3.824096711468883e-05\n",
      "Loss after epoch 3451 is 0.0000000002\n",
      "Weight and bias after 3461 epoch are 1.999987244606018 and 3.717642539413646e-05\n",
      "Loss after epoch 3461 is 0.0000000002\n",
      "Weight and bias after 3471 epoch are 1.9999876022338867 and 3.613929948187433e-05\n",
      "Loss after epoch 3471 is 0.0000000002\n",
      "Weight and bias after 3481 epoch are 1.9999878406524658 and 3.513794581522234e-05\n",
      "Loss after epoch 3481 is 0.0000000002\n",
      "Weight and bias after 3491 epoch are 1.9999881982803345 and 3.416997424210422e-05\n",
      "Loss after epoch 3491 is 0.0000000002\n",
      "Weight and bias after 3501 epoch are 1.9999885559082031 and 3.322107295389287e-05\n",
      "Loss after epoch 3501 is 0.0000000002\n",
      "Weight and bias after 3511 epoch are 1.9999887943267822 and 3.2316267606802285e-05\n",
      "Loss after epoch 3511 is 0.0000000002\n",
      "Weight and bias after 3521 epoch are 1.9999891519546509 and 3.144007860100828e-05\n",
      "Loss after epoch 3521 is 0.0000000002\n",
      "Weight and bias after 3531 epoch are 1.9999895095825195 and 3.058772563235834e-05\n",
      "Loss after epoch 3531 is 0.0000000002\n",
      "Weight and bias after 3541 epoch are 1.999989628791809 and 2.9755645300610922e-05\n",
      "Loss after epoch 3541 is 0.0000000001\n",
      "Weight and bias after 3551 epoch are 1.9999899864196777 and 2.8973632652196102e-05\n",
      "Loss after epoch 3551 is 0.0000000001\n",
      "Weight and bias after 3561 epoch are 1.9999903440475464 and 2.8207119612488896e-05\n",
      "Loss after epoch 3561 is 0.0000000001\n",
      "Weight and bias after 3571 epoch are 1.999990463256836 and 2.744060657278169e-05\n",
      "Loss after epoch 3571 is 0.0000000001\n",
      "Weight and bias after 3581 epoch are 1.999990701675415 and 2.672534537850879e-05\n",
      "Loss after epoch 3581 is 0.0000000001\n",
      "Weight and bias after 3591 epoch are 1.9999909400939941 and 2.603154644020833e-05\n",
      "Loss after epoch 3591 is 0.0000000001\n",
      "Weight and bias after 3601 epoch are 1.9999912977218628 and 2.5361594452988356e-05\n",
      "Loss after epoch 3601 is 0.0000000001\n",
      "Weight and bias after 3611 epoch are 1.9999914169311523 and 2.4684481104486622e-05\n",
      "Loss after epoch 3611 is 0.0000000001\n",
      "Weight and bias after 3621 epoch are 1.999991536140442 and 2.4049091734923422e-05\n",
      "Loss after epoch 3621 is 0.0000000001\n",
      "Weight and bias after 3631 epoch are 1.9999918937683105 and 2.345900793443434e-05\n",
      "Loss after epoch 3631 is 0.0000000001\n",
      "Weight and bias after 3641 epoch are 1.9999920129776 and 2.2853426344227046e-05\n",
      "Loss after epoch 3641 is 0.0000000001\n",
      "Weight and bias after 3651 epoch are 1.9999922513961792 and 2.2277645257418044e-05\n",
      "Loss after epoch 3651 is 0.0000000001\n",
      "Weight and bias after 3661 epoch are 1.9999923706054688 and 2.1707824998884462e-05\n",
      "Loss after epoch 3661 is 0.0000000001\n",
      "Weight and bias after 3671 epoch are 1.9999924898147583 and 2.1172572814975865e-05\n",
      "Loss after epoch 3671 is 0.0000000001\n",
      "Weight and bias after 3681 epoch are 1.9999927282333374 and 2.067428249574732e-05\n",
      "Loss after epoch 3681 is 0.0000000001\n",
      "Weight and bias after 3691 epoch are 1.9999929666519165 and 2.016526195802726e-05\n",
      "Loss after epoch 3691 is 0.0000000001\n",
      "Weight and bias after 3701 epoch are 1.9999932050704956 and 1.9686045561684296e-05\n",
      "Loss after epoch 3701 is 0.0000000001\n",
      "Weight and bias after 3711 epoch are 1.9999933242797852 and 1.919251553772483e-05\n",
      "Loss after epoch 3711 is 0.0000000001\n",
      "Weight and bias after 3721 epoch are 1.9999934434890747 and 1.8728795112110674e-05\n",
      "Loss after epoch 3721 is 0.0000000001\n",
      "Weight and bias after 3731 epoch are 1.9999935626983643 and 1.8294873370905407e-05\n",
      "Loss after epoch 3731 is 0.0000000001\n",
      "Weight and bias after 3741 epoch are 1.9999935626983643 and 1.787883047654759e-05\n",
      "Loss after epoch 3741 is 0.0000000001\n",
      "Weight and bias after 3751 epoch are 1.9999938011169434 and 1.746278940117918e-05\n",
      "Loss after epoch 3751 is 0.0000000001\n",
      "Weight and bias after 3761 epoch are 1.999993920326233 and 1.705985596345272e-05\n",
      "Loss after epoch 3761 is 0.0000000000\n",
      "Weight and bias after 3771 epoch are 1.999994158744812 and 1.6667652744217776e-05\n",
      "Loss after epoch 3771 is 0.0000000000\n",
      "Weight and bias after 3781 epoch are 1.9999942779541016 and 1.6281412172247656e-05\n",
      "Loss after epoch 3781 is 0.0000000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight and bias after 3791 epoch are 1.9999943971633911 and 1.591305226611439e-05\n",
      "Loss after epoch 3791 is 0.0000000000\n",
      "Weight and bias after 3801 epoch are 1.9999943971633911 and 1.556138704472687e-05\n",
      "Loss after epoch 3801 is 0.0000000000\n",
      "Weight and bias after 3811 epoch are 1.9999945163726807 and 1.5238329979183618e-05\n",
      "Loss after epoch 3811 is 0.0000000000\n",
      "Weight and bias after 3821 epoch are 1.9999947547912598 and 1.4929579265299253e-05\n",
      "Loss after epoch 3821 is 0.0000000000\n",
      "Weight and bias after 3831 epoch are 1.9999947547912598 and 1.4596987057302613e-05\n",
      "Loss after epoch 3831 is 0.0000000000\n",
      "Weight and bias after 3841 epoch are 1.9999948740005493 and 1.4282278243626934e-05\n",
      "Loss after epoch 3841 is 0.0000000000\n",
      "Weight and bias after 3851 epoch are 1.9999951124191284 and 1.4004522199684288e-05\n",
      "Loss after epoch 3851 is 0.0000000000\n",
      "Weight and bias after 3861 epoch are 1.9999951124191284 and 1.3685042176803108e-05\n",
      "Loss after epoch 3861 is 0.0000000000\n",
      "Weight and bias after 3871 epoch are 1.999995231628418 and 1.3395364476309624e-05\n",
      "Loss after epoch 3871 is 0.0000000000\n",
      "Weight and bias after 3881 epoch are 1.999995231628418 and 1.3114030480210204e-05\n",
      "Loss after epoch 3881 is 0.0000000000\n",
      "Weight and bias after 3891 epoch are 1.9999953508377075 and 1.2850575330958236e-05\n",
      "Loss after epoch 3891 is 0.0000000000\n",
      "Weight and bias after 3901 epoch are 1.999995470046997 and 1.2618120308616199e-05\n",
      "Loss after epoch 3901 is 0.0000000000\n",
      "Weight and bias after 3911 epoch are 1.999995470046997 and 1.2385662557790056e-05\n",
      "Loss after epoch 3911 is 0.0000000000\n",
      "Weight and bias after 3921 epoch are 1.999995470046997 and 1.2165123735030647e-05\n",
      "Loss after epoch 3921 is 0.0000000000\n",
      "Weight and bias after 3931 epoch are 1.9999957084655762 and 1.1939819160033949e-05\n",
      "Loss after epoch 3931 is 0.0000000000\n",
      "Weight and bias after 3941 epoch are 1.9999957084655762 and 1.1706169971148483e-05\n",
      "Loss after epoch 3941 is 0.0000000000\n",
      "Weight and bias after 3951 epoch are 1.9999958276748657 and 1.1486822586448397e-05\n",
      "Loss after epoch 3951 is 0.0000000000\n",
      "Weight and bias after 3961 epoch are 1.9999958276748657 and 1.1288931091257837e-05\n",
      "Loss after epoch 3961 is 0.0000000000\n",
      "Weight and bias after 3971 epoch are 1.9999960660934448 and 1.1092234672105405e-05\n",
      "Loss after epoch 3971 is 0.0000000000\n",
      "Weight and bias after 3981 epoch are 1.9999960660934448 and 1.0868124263652135e-05\n",
      "Loss after epoch 3981 is 0.0000000000\n",
      "Weight and bias after 3991 epoch are 1.9999961853027344 and 1.0671430572983809e-05\n",
      "Loss after epoch 3991 is 0.0000000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
    "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5], dtype=torch.float32)\n",
    "\n",
    "m,n = X.shape # m is the number of samples and n is the number of features\n",
    "\n",
    "input_size = n #For a single example\n",
    "output_size = n #For a single example\n",
    "\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "#Training\n",
    "learning_rate = 0.01\n",
    "epochs = 4000\n",
    "\n",
    "loss = nn.MSELoss() ## No need for hyperparameter setting here\n",
    "optimizer = opt.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    Y_pred = model(X)\n",
    "    l = loss(Y,Y_pred) ## Using the \"loss\" object that we created\n",
    "#     dw = gradient(X,Y,Y_pred)\n",
    "\n",
    "    l.backward()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         w -= learning_rate * w.grad\n",
    "\n",
    "    optimizer.step()\n",
    "   \n",
    "    #Resetting the gradient to 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if epoch%10==0:\n",
    "        [w, b] = model.parameters()\n",
    "        print(f'Weight and bias after {epoch+1} epoch are {w.item()} and {b.item()}')\n",
    "        print(f\"Loss after epoch {epoch+1} is {l:.10f}\")\n",
    "    \n",
    "\n",
    "print(f'Prediction after training: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9f598",
   "metadata": {},
   "source": [
    "NOTE : We haven't actually created a model on our own here. Since the problem statement is that of a simple regression, we have used a linear layer with just one unit as our model, by directly calling it from its package and setting all its parameters(input and output size)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
